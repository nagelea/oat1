#!/usr/bin/env python3
"""
GitHub Code Search Script
æœç´¢ GitHub ä»“åº“ä¸­çš„æ•æ„Ÿå†…å®¹
"""

import requests
import json
import os
import time
from datetime import datetime
from dateutil import parser
import base64
from typing import List, Dict, Optional


class GitHubSearcher:
    def __init__(self):
        self.token = os.environ.get('GITHUB_TOKEN')
        self.search_scope = os.environ.get('SEARCH_SCOPE', '')
        self.max_results = int(os.environ.get('MAX_RESULTS', '100'))
        self.search_pattern = os.environ.get('SEARCH_PATTERN', 'sk-ant-oat01-')
        self.file_extensions = os.environ.get('FILE_EXTENSIONS', 'json').split(',')
        
        if not self.token:
            raise ValueError("âŒ GITHUB_TOKEN æœªè®¾ç½®")
            
        self.headers = {
            'Authorization': f'token {self.token}',
            'Accept': 'application/vnd.github.v3+json',
            'X-GitHub-Api-Version': '2022-11-28'
        }
        
        # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
        os.makedirs('reports', exist_ok=True)
    
    def build_search_query(self) -> str:
        """æ„å»ºæœç´¢æŸ¥è¯¢"""
        # æ„å»ºè¯­è¨€æŸ¥è¯¢
        if len(self.file_extensions) == 1:
            language_query = f'language:{self.file_extensions[0]}'
        else:
            # å¤šä¸ªæ‰©å±•åç”¨ OR è¿æ¥
            ext_queries = [f'extension:{ext.strip()}' for ext in self.file_extensions]
            language_query = ' OR '.join(ext_queries)
            if len(ext_queries) > 1:
                language_query = f'({language_query})'
        
        base_query = f'{self.search_pattern} {language_query}'
        
        if self.search_scope:
            query = f'{base_query} {self.search_scope}'
        else:
            query = base_query
            
        return query
    
    def search_github_code(self) -> tuple[List[Dict], int]:
        """æ‰§è¡Œ GitHub ä»£ç æœç´¢"""
        query = self.build_search_query()
        print(f"ğŸ” æœç´¢æŸ¥è¯¢: {query}")
        print("=" * 80)
        
        results = []
        page = 1
        per_page = 30  # GitHub API é™åˆ¶
        total_found = 0
        
        while len(results) < self.max_results:
            try:
                print(f"ğŸ“„ æ­£åœ¨æœç´¢ç¬¬ {page} é¡µ...")
                
                # GitHub Code Search API
                search_url = 'https://api.github.com/search/code'
                params = {
                    'q': query,
                    'page': page,
                    'per_page': min(per_page, self.max_results - len(results))
                }
                
                response = requests.get(search_url, headers=self.headers, params=params)
                
                if response.status_code == 403:
                    print("âš ï¸  API é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… 60 ç§’...")
                    time.sleep(60)
                    continue
                elif response.status_code != 200:
                    print(f"âŒ API è¯·æ±‚å¤±è´¥: {response.status_code}")
                    print(f"å“åº”: {response.text}")
                    break
                
                data = response.json()
                total_found = data.get('total_count', 0)
                items = data.get('items', [])
                
                if not items:
                    print("âœ… æ²¡æœ‰æ›´å¤šç»“æœ")
                    break
                
                for item in items:
                    file_info = self.get_file_details(item)
                    if file_info:
                        results.append(file_info)
                
                page += 1
                time.sleep(1)  # é¿å… API é€Ÿç‡é™åˆ¶
                
            except Exception as e:
                print(f"âŒ æœç´¢é”™è¯¯: {e}")
                break
        
        print(f"\nğŸ“Š æœç´¢å®Œæˆ:")
        print(f"æ€»å…±æ‰¾åˆ°: {total_found} ä¸ªç»“æœ")
        print(f"å·²å¤„ç†: {len(results)} ä¸ªæ–‡ä»¶")
        
        return results, total_found
    
    def get_file_details(self, item: Dict) -> Optional[Dict]:
        """è·å–æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            repo_info = item['repository']
            file_path = item['path']
            
            print(f"  ğŸ“… è·å–æ–‡ä»¶ä¿¡æ¯: {repo_info['full_name']}/{file_path}")
            
            # è·å–æ—¶é—´å’Œæäº¤ä¿¡æ¯
            time_info = self._get_time_info(repo_info['full_name'], file_path)
            
            # è·å–æ–‡ä»¶å†…å®¹ä¿¡æ¯
            content_info = self._get_content_info(item)
            
            # è·å–å˜æ›´ä¿¡æ¯
            change_info = self._get_change_info(repo_info['full_name'], file_path, time_info)
            
            return {
                'repository': {
                    'name': repo_info['name'],
                    'full_name': repo_info['full_name'],
                    'owner': repo_info['owner']['login'],
                    'html_url': repo_info['html_url'],
                    'private': repo_info['private'],
                    'description': repo_info.get('description', ''),
                    'language': repo_info.get('language', ''),
                    'stars': repo_info.get('stargazers_count', 0),
                    'forks': repo_info.get('forks_count', 0),
                    'created_at': repo_info.get('created_at'),
                    'updated_at': repo_info.get('updated_at')
                },
                'file': {
                    'path': file_path,
                    'name': item['name'],
                    'html_url': item['html_url'],
                    'size': content_info.get('size', 0),
                    'match_count': content_info.get('match_count', 0)
                },
                'time_info': time_info,
                'change_info': change_info,
                'found_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"âš ï¸  è·å–æ–‡ä»¶è¯¦æƒ…å¤±è´¥ {item.get('path', 'unknown')}: {e}")
            return None
    
    def _get_time_info(self, repo_full_name: str, file_path: str) -> Dict:
        """è·å–æ–‡ä»¶çš„æ—¶é—´ä¿¡æ¯"""
        time_info = {
            'first_commit': {},
            'last_commit': {},
            'commit_history': [],
            'total_commits': 0,
            'file_age_days': None
        }
        
        try:
            # è·å–æ‰€æœ‰æäº¤è®°å½•
            commits_url = f"https://api.github.com/repos/{repo_full_name}/commits"
            params = {'path': file_path, 'per_page': 100}
            
            response = requests.get(commits_url, headers=self.headers, params=params)
            
            if response.status_code == 200:
                commits_data = response.json()
                
                if commits_data:
                    # æœ€æ–°æäº¤
                    latest_commit = commits_data[0]
                    time_info['last_commit'] = {
                        'last_modified': latest_commit['commit']['committer']['date'],
                        'last_commit_sha': latest_commit['sha'],
                        'last_commit_message': self._truncate_message(latest_commit['commit']['message']),
                        'last_author': latest_commit['commit']['author']['name'],
                        'last_author_email': latest_commit['commit']['author']['email'],
                        'last_committer': latest_commit['commit']['committer']['name'],
                        'last_committer_date': latest_commit['commit']['committer']['date']
                    }
                    
                    # æœ€æ—©æäº¤
                    oldest_commit = commits_data[-1]
                    time_info['first_commit'] = {
                        'first_created': oldest_commit['commit']['author']['date'],
                        'first_commit_sha': oldest_commit['sha'],
                        'first_commit_message': self._truncate_message(oldest_commit['commit']['message']),
                        'first_author': oldest_commit['commit']['author']['name'],
                        'first_author_email': oldest_commit['commit']['author']['email'],
                        'creation_committer': oldest_commit['commit']['committer']['name'],
                        'creation_committer_date': oldest_commit['commit']['committer']['date']
                    }
                    
                    # è®¡ç®—æ–‡ä»¶å¹´é¾„
                    try:
                        created_date = parser.parse(oldest_commit['commit']['author']['date'])
                        file_age = (datetime.now(created_date.tzinfo) - created_date).days
                        time_info['file_age_days'] = file_age
                    except:
                        pass
                    
                    # æäº¤å†å²
                    time_info['total_commits'] = len(commits_data)
                    for commit in commits_data[:10]:  # å‰10æ¬¡æäº¤
                        time_info['commit_history'].append({
                            'sha': commit['sha'][:8],
                            'date': commit['commit']['author']['date'],
                            'author': commit['commit']['author']['name'],
                            'message': self._truncate_message(commit['commit']['message'], 50),
                            'committer_date': commit['commit']['committer']['date']
                        })
        
        except Exception as e:
            print(f"    âš ï¸ è·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
        
        return time_info
    
    def _get_content_info(self, item: Dict) -> Dict:
        """è·å–æ–‡ä»¶å†…å®¹ä¿¡æ¯"""
        content_info = {'size': 0, 'match_count': 0}
        
        try:
            content_url = item['url']
            response = requests.get(content_url, headers=self.headers)
            
            if response.status_code == 200:
                content_data = response.json()
                content_info['size'] = content_data.get('size', 0)
                
                if content_data.get('content'):
                    try:
                        decoded_content = base64.b64decode(content_data['content']).decode('utf-8')
                        content_info['match_count'] = decoded_content.count(self.search_pattern)
                    except:
                        pass
        
        except Exception as e:
            print(f"    âš ï¸ è·å–å†…å®¹ä¿¡æ¯å¤±è´¥: {e}")
        
        return content_info
    
    def _get_change_info(self, repo_full_name: str, file_path: str, time_info: Dict) -> Dict:
        """è·å–æ–‡ä»¶å˜æ›´ä¿¡æ¯"""
        change_info = {}
        
        try:
            last_commit_sha = time_info.get('last_commit', {}).get('last_commit_sha')
            if last_commit_sha:
                commit_url = f"https://api.github.com/repos/{repo_full_name}/commits/{last_commit_sha}"
                response = requests.get(commit_url, headers=self.headers)
                
                if response.status_code == 200:
                    commit_detail = response.json()
                    files_changed = commit_detail.get('files', [])
                    
                    for file_change in files_changed:
                        if file_change.get('filename') == file_path:
                            change_info = {
                                'additions': file_change.get('additions', 0),
                                'deletions': file_change.get('deletions', 0),
                                'changes': file_change.get('changes', 0),
                                'status': file_change.get('status', 'unknown'),
                                'previous_filename': file_change.get('previous_filename')
                            }
                            break
        
        except Exception as e:
            print(f"    âš ï¸ è·å–å˜æ›´ä¿¡æ¯å¤±è´¥: {e}")
        
        return change_info
    
    def _truncate_message(self, message: str, max_length: int = 100) -> str:
        """æˆªæ–­æäº¤æ¶ˆæ¯"""
        if len(message) > max_length:
            return message[:max_length] + '...'
        return message
    
    def save_raw_data(self, results: List[Dict], total_found: int):
        """ä¿å­˜åŸå§‹æ•°æ®"""
        raw_data = {
            'scan_time': datetime.now().isoformat(),
            'search_query': self.build_search_query(),
            'search_pattern': self.search_pattern,
            'file_extensions': self.file_extensions,
            'search_scope': self.search_scope,
            'total_found': total_found,
            'analyzed_files': len(results),
            'results': results
        }
        
        with open('reports/raw_data.json', 'w', encoding='utf-8') as f:
            json.dump(raw_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ åŸå§‹æ•°æ®å·²ä¿å­˜åˆ° reports/raw_data.json")


def main():
    """ä¸»å‡½æ•°"""
    try:
        print("ğŸš€ å¼€å§‹ GitHub ä»£ç æœç´¢...")
        
        searcher = GitHubSearcher()
        results, total_found = searcher.search_github_code()
        
        print(f"\nğŸ’¾ ä¿å­˜åŸå§‹æ•°æ®...")
        searcher.save_raw_data(results, total_found)
        
        print(f"\nâœ… æœç´¢å®Œæˆï¼")
        if results:
            print(f"âš ï¸  å‘ç° {len(results)} ä¸ªæ–‡ä»¶åŒ…å«æ•æ„Ÿå†…å®¹")
            print(f"ğŸ” æ¶‰åŠ {len(set(r['repository']['full_name'] for r in results))} ä¸ªä»“åº“")
            public_count = sum(1 for r in results if not r['repository']['private'])
            if public_count > 0:
                print(f"ğŸš¨ è­¦å‘Š: {public_count} ä¸ªæ–‡ä»¶åœ¨å…¬å¼€ä»“åº“ä¸­!")
        else:
            print("âœ… æœªå‘ç°æ•æ„Ÿå†…å®¹")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        exit(1)


if __name__ == "__main__":
    main()
