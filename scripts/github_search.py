#!/usr/bin/env python3
"""
æ–°å‘ç°æ£€æŸ¥è„šæœ¬
æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ•æ„Ÿå†…å®¹å‘ç°
"""

import json
import os
import hashlib
from datetime import datetime


def calculate_results_hash(results_file='reports/raw_data.json'):
    """è®¡ç®—ç»“æœçš„å“ˆå¸Œå€¼"""
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æå–å…³é”®ä¿¡æ¯ç”¨äºå“ˆå¸Œè®¡ç®—
        key_data = []
        for result in data.get('results', []):
            key_info = {
                'repo': result['repository']['full_name'],
                'file': result['file']['path'],
                'matches': result['file']['match_count'],
                'last_modified': result.get('time_info', {}).get('last_commit', {}).get('last_modified', '')
            }
            key_data.append(key_info)
        
        # æŒ‰ä»“åº“å’Œæ–‡ä»¶è·¯å¾„æ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§
        key_data.sort(key=lambda x: (x['repo'], x['file']))
        
        # è®¡ç®—å“ˆå¸Œ
        content = json.dumps(key_data, sort_keys=True).encode()
        return hashlib.sha256(content).hexdigest()
        
    except FileNotFoundError:
        print("âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨")
        return None
    except Exception as e:
        print(f"âŒ è®¡ç®—å“ˆå¸Œå¤±è´¥: {e}")
        return None


def check_for_new_findings():
    """æ£€æŸ¥æ˜¯å¦æœ‰æ–°å‘ç°"""
    current_hash = calculate_results_hash()
    previous_hash = os.environ.get('PREVIOUS_HASH', '')
    
    if not current_hash:
        print("âŒ æ— æ³•è®¡ç®—å½“å‰ç»“æœå“ˆå¸Œ")
        return False, {}
    
    print(f"ğŸ“Š å½“å‰ç»“æœå“ˆå¸Œ: {current_hash[:12]}...")
    print(f"ğŸ“Š ä¸Šæ¬¡ç»“æœå“ˆå¸Œ: {previous_hash[:12] if previous_hash else 'None'}...")
    
    # å¦‚æœæ˜¯é¦–æ¬¡è¿è¡Œæˆ–å“ˆå¸Œä¸åŒï¼Œåˆ™è®¤ä¸ºæœ‰æ–°å‘ç°
    has_new_findings = (not previous_hash) or (current_hash != previous_hash)
    
    # åŠ è½½å½“å‰ç»“æœ
    try:
        with open('reports/raw_data.json', 'r', encoding='utf-8') as f:
            current_data = json.load(f)
    except:
        current_data = {'results': []}
    
    # åˆ†ææ–°å‘ç°çš„è¯¦æƒ…
    new_findings_info = analyze_findings(current_data, has_new_findings, previous_hash)
    
    return has_new_findings, new_findings_info


def analyze_findings(current_data, has_new_findings, previous_hash):
    """åˆ†æå‘ç°çš„è¯¦æƒ…"""
    results = current_data.get('results', [])
    total_files = len(results)
    public_files = sum(1 for r in results if not r['repository']['private'])
    total_matches = sum(r['file']['match_count'] for r in results)
    
    # é£é™©ç­‰çº§
    if public_files > 0:
        if total_matches > 10:
            risk_level = "ğŸš¨ CRITICAL"
        elif total_matches > 5:
            risk_level = "âš ï¸ HIGH"
        else:
            risk_level = "ğŸŸ¡ MEDIUM"
    elif total_files > 0:
        risk_level = "ğŸŸ¢ LOW"
    else:
        risk_level = "âœ… NONE"
    
    # æ„å»ºåˆ†æç»“æœ
    analysis = {
        'scan_time': current_data.get('scan_time', datetime.now().isoformat()),
        'is_first_scan': not previous_hash,
        'total_files': total_files,
        'public_files': public_files,
        'private_files': total_files - public_files,
        'total_matches': total_matches,
        'risk_level': risk_level,
        'repositories': list(set(r['repository']['full_name'] for r in results)),
        'top_repositories': get_top_repositories(results),
        'file_types': get_file_type_distribution(results)
    }
    
    return analysis


def get_top_repositories(results):
    """è·å–åŒ¹é…æœ€å¤šçš„ä»“åº“"""
    repo_matches = {}
    for result in results:
        repo_name = result['repository']['full_name']
        matches = result['file']['match_count']
        
        if repo_name not in repo_matches:
            repo_matches[repo_name] = {
                'name': repo_name,
                'total_matches': 0,
                'file_count': 0,
                'is_private': result['repository']['private']
            }
        
        repo_matches[repo_name]['total_matches'] += matches
        repo_matches[repo_name]['file_count'] += 1
    
    # æŒ‰åŒ¹é…æ•°æ’åº
    top_repos = sorted(repo_matches.values(), key=lambda x: x['total_matches'], reverse=True)
    return top_repos[:5]  # è¿”å›å‰5ä¸ª


def get_file_type_distribution(results):
    """è·å–æ–‡ä»¶ç±»å‹åˆ†å¸ƒ"""
    file_types = {}
    for result in results:
        file_path = result['file']['path']
        ext = file_path.split('.')[-1].lower() if '.' in file_path else 'no_extension'
        
        if ext not in file_types:
            file_types[ext] = {
                'count': 0,
                'total_matches': 0
            }
        
        file_types[ext]['count'] += 1
        file_types[ext]['total_matches'] += result['file']['match_count']
    
    return dict(sorted(file_types.items(), key=lambda x: x[1]['count'], reverse=True))


def save_check_results(has_new_findings, analysis):
    """ä¿å­˜æ£€æŸ¥ç»“æœ"""
    check_results = {
        'has_new_findings': has_new_findings,
        'check_time': datetime.now().isoformat(),
        'analysis': analysis
    }
    
    os.makedirs('reports', exist_ok=True)
    with open('reports/new_findings_check.json', 'w', encoding='utf-8') as f:
        json.dump(check_results, f, indent=2, ensure_ascii=False)
    
    # è®¾ç½® GitHub Actions è¾“å‡º
    with open(os.environ.get('GITHUB_OUTPUT', '/dev/stdout'), 'a') as f:
        f.write(f"has_new_findings={'true' if has_new_findings else 'false'}\n")
        f.write(f"total_files={analysis['total_files']}\n")
        f.write(f"public_files={analysis['public_files']}\n")
        f.write(f"risk_level={analysis['risk_level']}\n")
    
    print(f"âœ… æ£€æŸ¥å®Œæˆ: {'å‘ç°æ–°å†…å®¹' if has_new_findings else 'æ— æ–°å‘ç°'}")
    print(f"ğŸ“Š æ€»æ–‡ä»¶æ•°: {analysis['total_files']}")
    print(f"ğŸŒ å…¬å¼€ä»“åº“æ–‡ä»¶: {analysis['public_files']}")
    print(f"ğŸ”’ ç§æœ‰ä»“åº“æ–‡ä»¶: {analysis['private_files']}")
    print(f"âš ï¸ é£é™©ç­‰çº§: {analysis['risk_level']}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        print("ğŸ” æ£€æŸ¥æ–°å‘ç°...")
        has_new_findings, analysis = check_for_new_findings()
        save_check_results(has_new_findings, analysis)
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        # è®¾ç½®é»˜è®¤è¾“å‡ºï¼Œé¿å…åç»­æ­¥éª¤å¤±è´¥
        with open(os.environ.get('GITHUB_OUTPUT', '/dev/stdout'), 'a') as f:
            f.write("has_new_findings=false\n")
            f.write("total_files=0\n")
            f.write("public_files=0\n")
            f.write("risk_level=UNKNOWN\n")
        exit(1)


if __name__ == "__main__":
    main()
