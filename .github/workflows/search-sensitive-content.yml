# 提取关键信息
          python << 'EOF'
        import json
        import os
        
        try:
            with open('detailed_report.json', 'r') as f:
                data = json.load(f)
            
            summary = data.get('summary', {})
            total_found = data.get('total_found', 0)
            analyzed = data.get('analyzed_files', 0)
            
            with open(os.environ['GITHUB_STEP_SUMMARY'], 'a') as f:
                f.write(f"- **总共发现**: {total_found} 个匹配项\n")
                f.write(f"- **已分析文件**: {analyzed} 个\n")
                f.write(f"- **公开仓库**: {summary.get('public_repos', 0)} 个文件\n")
                f.write(f"- **私有仓库**: {summary.get('private_repos', 0)} 个文件\n")
                f.write(f"- **总匹配次数**: {summary.get('total_matches', 0)} 次\n")
                f.write(f"- **涉及仓库数**: {len(summary.get('repositories', []))}\n")
                f.write(f"- **总提交次数**: {summary.get('total_commits', 0)}\n")
                f.write(f"- **最老文件**: {summary.get('oldest_file_days', 0)} 天前创建\n")
                f.write(f"- **最新文件**: {summary.get('newest_file_days', 0)} 天前创建\n")
                f.write(f"- **涉及作者数**: {len(summary.get('authors', []))}\n\n")
                
                if summary.get('public_repos', 0) > 0:
                    f.write("🚨 **安全警告**: 在公开仓库中发现敏感内容!\n\n")
                
                f.write("### 📋 涉及的仓库\n")
                for repo in summary.get('repositories', [])[:10]:  # 只显示前10个
                    f.writename: GitHub Code Search for Sensitive Content

on:
  workflow_dispatch:  # 手动触发
    inputs:
      search_scope:
        description: '搜索范围 (user:username 或 org:orgname，留空搜索所有公开仓库)'
        required: false
        default: ''
      max_results:
        description: '最大结果数量'
        required: false
        default: '100'
  schedule:
    - cron: '0 2 * * *'  # 每天凌晨2点运行

jobs:
  github-code-search:
    runs-on: ubuntu-latest
    
    steps:
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        pip install requests python-dateutil

    - name: Search GitHub Code for sensitive content
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SEARCH_SCOPE: ${{ github.event.inputs.search_scope }}
        MAX_RESULTS: ${{ github.event.inputs.max_results || '100' }}
      run: |
        cat > github_search.py << 'EOF'
        import requests
        import json
        import os
        from datetime import datetime
        from dateutil import parser
        import time
        
        def search_github_code():
            token = os.environ.get('GITHUB_TOKEN')
            search_scope = os.environ.get('SEARCH_SCOPE', '')
            max_results = int(os.environ.get('MAX_RESULTS', '100'))
            
            if not token:
                print("❌ GITHUB_TOKEN 未设置")
                return []
            
            headers = {
                'Authorization': f'token {token}',
                'Accept': 'application/vnd.github.v3+json',
                'X-GitHub-Api-Version': '2022-11-28'
            }
            
            # 构建搜索查询
            base_query = 'sk-ant-oat01- language:json'
            if search_scope:
                query = f'{base_query} {search_scope}'
            else:
                query = base_query
            
            print(f"🔍 搜索查询: {query}")
            print("=" * 50)
            
            results = []
            page = 1
            per_page = 30  # GitHub API 限制
            total_found = 0
            
            while len(results) < max_results:
                try:
                    # GitHub Code Search API
                    search_url = 'https://api.github.com/search/code'
                    params = {
                        'q': query,
                        'page': page,
                        'per_page': min(per_page, max_results - len(results))
                    }
                    
                    print(f"📄 正在搜索第 {page} 页...")
                    response = requests.get(search_url, headers=headers, params=params)
                    
                    if response.status_code == 403:
                        print("⚠️  API 速率限制，等待 60 秒...")
                        time.sleep(60)
                        continue
                    elif response.status_code != 200:
                        print(f"❌ API 请求失败: {response.status_code}")
                        print(f"响应: {response.text}")
                        break
                    
                    data = response.json()
                    total_found = data.get('total_count', 0)
                    items = data.get('items', [])
                    
                    if not items:
                        print("✅ 没有更多结果")
                        break
                    
                    for item in items:
                        # 获取文件的详细信息
                        file_info = get_file_details(item, headers)
                        if file_info:
                            results.append(file_info)
                    
                    page += 1
                    
                    # 避免 API 速率限制
                    time.sleep(1)
                    
                except Exception as e:
                    print(f"❌ 搜索错误: {e}")
                    break
            
            print(f"\n📊 搜索完成:")
            print(f"总共找到: {total_found} 个结果")
            print(f"已处理: {len(results)} 个文件")
            
            return results, total_found
        
        def get_file_details(item, headers):
            try:
                repo_info = item['repository']
                file_path = item['path']
                
                # 获取文件的完整提交历史
                print(f"  📅 获取文件时间信息: {file_path}")
                
                # 1. 获取所有相关的提交记录（包括重命名和移动）
                commits_url = f"https://api.github.com/repos/{repo_info['full_name']}/commits"
                all_commits_params = {
                    'path': file_path,
                    'per_page': 100  # 获取更多历史记录
                }
                
                all_commits_response = requests.get(commits_url, headers=headers, params=all_commits_params)
                commit_history = []
                first_commit_info = {}
                last_commit_info = {}
                
                if all_commits_response.status_code == 200:
                    all_commits_data = all_commits_response.json()
                    
                    if all_commits_data:
                        # 最后一次修改（最新提交）
                        latest_commit = all_commits_data[0]
                        last_commit_info = {
                            'last_modified': latest_commit['commit']['committer']['date'],
                            'last_commit_sha': latest_commit['sha'],
                            'last_commit_message': latest_commit['commit']['message'][:100] + '...' if len(latest_commit['commit']['message']) > 100 else latest_commit['commit']['message'],
                            'last_author': latest_commit['commit']['author']['name'],
                            'last_author_email': latest_commit['commit']['author']['email'],
                            'last_committer': latest_commit['commit']['committer']['name'],
                            'last_committer_date': latest_commit['commit']['committer']['date']
                        }
                        
                        # 首次创建（最早提交）
                        oldest_commit = all_commits_data[-1]
                        first_commit_info = {
                            'first_created': oldest_commit['commit']['author']['date'],
                            'first_commit_sha': oldest_commit['sha'],
                            'first_commit_message': oldest_commit['commit']['message'][:100] + '...' if len(oldest_commit['commit']['message']) > 100 else oldest_commit['commit']['message'],
                            'first_author': oldest_commit['commit']['author']['name'],
                            'first_author_email': oldest_commit['commit']['author']['email'],
                            'creation_committer': oldest_commit['commit']['committer']['name'],
                            'creation_committer_date': oldest_commit['commit']['committer']['date']
                        }
                        
                        # 构建修改历史
                        for commit in all_commits_data[:10]:  # 只取前10次修改
                            commit_history.append({
                                'sha': commit['sha'][:8],
                                'date': commit['commit']['author']['date'],
                                'author': commit['commit']['author']['name'],
                                'message': commit['commit']['message'][:50] + '...' if len(commit['commit']['message']) > 50 else commit['commit']['message'],
                                'committer_date': commit['commit']['committer']['date']
                            })
                
                # 2. 尝试获取文件的详细统计信息
                file_stats = {}
                try:
                    # 获取文件的贡献者统计
                    contributors_url = f"https://api.github.com/repos/{repo_info['full_name']}/stats/contributors"
                    contributors_response = requests.get(contributors_url, headers=headers)
                    
                    # 注意：这个 API 可能需要时间生成统计，第一次调用可能返回 202
                    if contributors_response.status_code == 200:
                        contributors_data = contributors_response.json()
                        total_contributors = len(contributors_data) if contributors_data else 0
                        file_stats['total_contributors'] = total_contributors
                except:
                    pass
                
                # 3. 获取文件的具体变更信息
                file_changes = {}
                if all_commits_data:
                    try:
                        # 获取最近一次提交的详细信息，包括文件变更
                        commit_detail_url = f"https://api.github.com/repos/{repo_info['full_name']}/commits/{all_commits_data[0]['sha']}"
                        commit_detail_response = requests.get(commit_detail_url, headers=headers)
                        
                        if commit_detail_response.status_code == 200:
                            commit_detail = commit_detail_response.json()
                            files_changed = commit_detail.get('files', [])
                            
                            # 查找当前文件的变更信息
                            for file_change in files_changed:
                                if file_change.get('filename') == file_path:
                                    file_changes = {
                                        'additions': file_change.get('additions', 0),
                                        'deletions': file_change.get('deletions', 0),
                                        'changes': file_change.get('changes', 0),
                                        'status': file_change.get('status', 'unknown'),  # added, modified, deleted, renamed
                                        'previous_filename': file_change.get('previous_filename')
                                    }
                                    break
                    except:
                        pass
                
                # 获取文件内容以计算匹配次数（注意：这会消耗更多API调用）
                content_url = item['url']
                content_response = requests.get(content_url, headers=headers)
                match_count = 0
                file_size = 0
                
                if content_response.status_code == 200:
                    content_data = content_response.json()
                    if content_data.get('content'):
                        import base64
                        try:
                            decoded_content = base64.b64decode(content_data['content']).decode('utf-8')
                            match_count = decoded_content.count('sk-ant-oat01-')
                            file_size = content_data.get('size', 0)
                        except:
                            pass
                
                return {
                    'repository': {
                        'name': repo_info['name'],
                        'full_name': repo_info['full_name'],
                        'owner': repo_info['owner']['login'],
                        'html_url': repo_info['html_url'],
                        'private': repo_info['private'],
                        'description': repo_info.get('description', ''),
                        'language': repo_info.get('language', ''),
                        'stars': repo_info.get('stargazers_count', 0),
                        'forks': repo_info.get('forks_count', 0)
                    },
                    'file': {
                        'path': file_path,
                        'name': item['name'],
                        'html_url': item['html_url'],
                        'size': file_size,
                        'match_count': match_count
                    },
                    'time_info': {
                        'first_commit': first_commit_info,
                        'last_commit': last_commit_info,
                        'commit_history': commit_history,
                        'total_commits': len(commit_history),
                        'file_age_days': None  # 将在后面计算
                    },
                    'change_info': file_changes,
                    'stats': file_stats,
                    'found_at': datetime.now().isoformat()
                }
                
            except Exception as e:
                print(f"⚠️  获取文件详情失败 {item['path']}: {e}")
                return None
        
        def generate_reports(results, total_found):
            # 计算文件年龄等额外信息
            for result in results:
                time_info = result.get('time_info', {})
                first_commit = time_info.get('first_commit', {})
                if first_commit.get('first_created'):
                    try:
                        created_date = parser.parse(first_commit['first_created'])
                        file_age = (datetime.now(created_date.tzinfo) - created_date).days
                        time_info['file_age_days'] = file_age
                    except:
                        pass
            
            # 生成文本报告
            with open('search_results.txt', 'w', encoding='utf-8') as f:
                f.write(f"GitHub 代码搜索结果 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 80 + "\n")
                f.write(f"搜索查询: sk-ant-oat01- language:json\n")
                f.write(f"总共找到: {total_found} 个结果\n")
                f.write(f"已分析: {len(results)} 个文件\n\n")
                
                if not results:
                    f.write("✅ 未发现包含敏感内容的文件\n")
                else:
                    f.write("⚠️  发现以下文件包含敏感内容:\n\n")
                    
                    for i, result in enumerate(results, 1):
                        repo = result['repository']
                        file_info = result['file']
                        time_info = result.get('time_info', {})
                        first_commit = time_info.get('first_commit', {})
                        last_commit = time_info.get('last_commit', {})
                        change_info = result.get('change_info', {})
                        
                        f.write(f"{i}. 仓库: {repo['full_name']}\n")
                        f.write(f"   文件: {file_info['path']}\n")
                        f.write(f"   URL: {file_info['html_url']}\n")
                        f.write(f"   仓库类型: {'私有' if repo['private'] else '公开'}\n")
                        f.write(f"   文件大小: {file_info['size']} bytes\n")
                        f.write(f"   匹配次数: {file_info['match_count']}\n")
                        
                        # 详细时间信息
                        f.write(f"\n   📅 时间信息:\n")
                        if first_commit:
                            f.write(f"   ├─ 首次创建: {first_commit.get('first_created', 'N/A')}\n")
                            f.write(f"   ├─ 创建作者: {first_commit.get('first_author', 'N/A')}\n")
                            f.write(f"   ├─ 创建提交: {first_commit.get('first_commit_sha', 'N/A')[:8]}\n")
                            f.write(f"   ├─ 创建消息: {first_commit.get('first_commit_message', 'N/A')}\n")
                        
                        if last_commit:
                            f.write(f"   ├─ 最后修改: {last_commit.get('last_modified', 'N/A')}\n")
                            f.write(f"   ├─ 修改作者: {last_commit.get('last_author', 'N/A')}\n")
                            f.write(f"   ├─ 最新提交: {last_commit.get('last_commit_sha', 'N/A')[:8]}\n")
                            f.write(f"   ├─ 提交消息: {last_commit.get('last_commit_message', 'N/A')}\n")
                        
                        file_age = time_info.get('file_age_days')
                        if file_age is not None:
                            f.write(f"   ├─ 文件年龄: {file_age} 天\n")
                        
                        total_commits = time_info.get('total_commits', 0)
                        f.write(f"   └─ 总提交数: {total_commits}\n")
                        
                        # 变更信息
                        if change_info:
                            f.write(f"\n   📊 最近变更:\n")
                            f.write(f"   ├─ 状态: {change_info.get('status', 'N/A')}\n")
                            f.write(f"   ├─ 新增行数: {change_info.get('additions', 0)}\n")
                            f.write(f"   ├─ 删除行数: {change_info.get('deletions', 0)}\n")
                            f.write(f"   └─ 总变更行数: {change_info.get('changes', 0)}\n")
                            if change_info.get('previous_filename'):
                                f.write(f"   └─ 原文件名: {change_info['previous_filename']}\n")
                        
                        # 修改历史
                        commit_history = time_info.get('commit_history', [])
                        if commit_history:
                            f.write(f"\n   📝 最近修改历史:\n")
                            for j, commit in enumerate(commit_history[:5], 1):
                                f.write(f"   {j}. {commit['date'][:10]} - {commit['author']} - {commit['message']}\n")
                        
                        f.write(f"\n   🏢 仓库信息:\n")
                        f.write(f"   ├─ 描述: {repo['description']}\n")
                        f.write(f"   ├─ 主要语言: {repo['language']}\n")
                        f.write(f"   └─ Stars: {repo['stars']}, Forks: {repo['forks']}\n")
                        
                        f.write("\n" + "=" * 80 + "\n\n")
            
            # 生成 JSON 报告
            report_data = {
                'scan_time': datetime.now().isoformat(),
                'search_query': 'sk-ant-oat01- language:json',
                'total_found': total_found,
                'analyzed_files': len(results),
                'results': results,
                'summary': {
                    'public_repos': sum(1 for r in results if not r['repository']['private']),
                    'private_repos': sum(1 for r in results if r['repository']['private']),
                    'total_matches': sum(r['file']['match_count'] for r in results),
                    'repositories': list(set(r['repository']['full_name'] for r in results)),
                    'oldest_file_days': max((r.get('time_info', {}).get('file_age_days', 0) for r in results), default=0),
                    'newest_file_days': min((r.get('time_info', {}).get('file_age_days', float('inf')) for r in results if r.get('time_info', {}).get('file_age_days') is not None), default=0),
                    'total_commits': sum(r.get('time_info', {}).get('total_commits', 0) for r in results),
                    'authors': list(set(
                        author for r in results 
                        for author in [
                            r.get('time_info', {}).get('first_commit', {}).get('first_author'),
                            r.get('time_info', {}).get('last_commit', {}).get('last_author')
                        ] if author
                    ))
                }
            }
            
            with open('detailed_report.json', 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        # 执行搜索
        print("🚀 开始 GitHub 代码搜索...")
        results, total_found = search_github_code()
        
        print(f"\n📝 生成报告...")
        generate_reports(results, total_found)
        
        print(f"\n✅ 搜索完成！")
        if results:
            print(f"⚠️  发现 {len(results)} 个文件包含敏感内容")
            print(f"🔍 涉及 {len(set(r['repository']['full_name'] for r in results))} 个仓库")
            public_count = sum(1 for r in results if not r['repository']['private'])
            if public_count > 0:
                print(f"🚨 警告: {public_count} 个文件在公开仓库中!")
        else:
            print("✅ 未发现敏感内容")
        EOF
        
        python github_search.py

    - name: Upload search results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: github-code-search-results-${{ github.run_number }}
        path: |
          search_results.txt
          detailed_report.json
        retention-days: 30

    - name: Create security alert summary
      if: always()
      run: |
        if [ -f "detailed_report.json" ]; then
          echo "## 🔍 GitHub 代码搜索结果" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # 提取关键信息
          python << 'EOF'
        import json
        import os
        
        try:
            with open('detailed_report.json', 'r') as f:
                data = json.load(f)
            
            summary = data.get('summary', {})
            total_found = data.get('total_found', 0)
            analyzed = data.get('analyzed_files', 0)
            
            with open(os.environ['GITHUB_STEP_SUMMARY'], 'a') as f:
                f.write(f"- **总共发现**: {total_found} 个匹配项\n")
                f.write(f"- **已分析文件**: {analyzed} 个\n")
                f.write(f"- **公开仓库**: {summary.get('public_repos', 0)} 个文件\n")
                f.write(f"- **私有仓库**: {summary.get('private_repos', 0)} 个文件\n")
                f.write(f"- **总匹配次数**: {summary.get('total_matches', 0)} 次\n")
                f.write(f"- **涉及仓库数**: {len(summary.get('repositories', []))}\n")
                f.write(f"- **总提交次数**: {summary.get('total_commits', 0)}\n")
                f.write(f"- **最老文件**: {summary.get('oldest_file_days', 0)} 天前创建\n")
                f.write(f"- **最新文件**: {summary.get('newest_file_days', 0)} 天前创建\n")
                f.write(f"- **涉及作者数**: {len(summary.get('authors', []))}\n\n")
                
                if summary.get('public_repos', 0) > 0:
                    f.write("🚨 **安全警告**: 在公开仓库中发现敏感内容!\n\n")
                
                f.write("### 📋 涉及的仓库\n")
                for repo in summary.get('repositories', [])[:10]:  # 只显示前10个
                    f.write(f"- {repo}\n")
                
                if len(summary.get('repositories', [])) > 10:
                    f.write(f"- ... 还有 {len(summary.get('repositories', [])) - 10} 个仓库\n")
                
                # 显示涉及的作者
                authors = summary.get('authors', [])
                if authors:
                    f.write(f"\n### 👥 涉及的作者 (前10位)\n")
                    for author in authors[:10]:
                        f.write(f"- {author}\n")
                    if len(authors) > 10:
                        f.write(f"- ... 还有 {len(authors) - 10} 位作者\n")
        except Exception as e:
            print(f"生成摘要失败: {e}")
        EOF
        fi

    - name: Security recommendations
      if: always()
      run: |
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## 🔒 安全建议" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "1. **立即行动**: 如果在公开仓库中发现敏感内容，请立即更换相关的 API 密钥" >> $GITHUB_STEP_SUMMARY
        echo "2. **清理历史**: 使用 git filter-branch 或 BFG Repo-Cleaner 清理 Git 历史记录" >> $GITHUB_STEP_SUMMARY
        echo "3. **联系仓库所有者**: 如果敏感内容在他人仓库中，请联系仓库所有者" >> $GITHUB_STEP_SUMMARY
        echo "4. **启用监控**: 考虑使用 GitHub secret scanning 或其他安全工具" >> $GITHUB_STEP_SUMMARY
        echo "5. **预防措施**: 使用 pre-commit hooks 和 .gitignore 防止未来泄露" >> $GITHUB_STEP_SUMMARY
